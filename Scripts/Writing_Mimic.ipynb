{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "writing mimic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set variables, import deps, give model something to write about, and tell it how many times to iteratively improve writing mimic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import anthropic\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Set up Anthropic API client\n",
    "api_key = \"YOUR_API_KEY\"  # replace this, clod\n",
    "client = anthropic.Client(api_key)\n",
    "\n",
    "# Set sampling parameters\n",
    "model = \"claude-3-sonnet-20240229\"\n",
    "temperature = 0.7\n",
    "top_p = 1\n",
    "\n",
    "# Load sample texts from directory\n",
    "samples_dir = \"samples/\"\n",
    "sample_texts = []\n",
    "for file_name in os.listdir(samples_dir):\n",
    "    file_path = os.path.join(samples_dir, file_name)\n",
    "    with open(file_path, \"r\") as file:\n",
    "        sample_texts.append(file.read())\n",
    "\n",
    "topic = input(\"Enter the topic or information to write about: \")  # Prompt user for information to write about\n",
    "num_iterations = int(input(\"Enter the number of iterations to perform: \"))  # Set number of iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first mimicked text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"Analyze the following sample texts to understand the writing style:\\n\\n{sample_texts}\\n\\nNow, write a text about the following topic in the same style as the sample texts:\\n{topic}\"\n",
    "response = client.completions.create(\n",
    "    prompt=prompt,\n",
    "    model=model,\n",
    "    temperature=temperature,\n",
    "    top_p=top_p,\n",
    "    max_tokens=500\n",
    ")\n",
    "mimicked_text = response.completions[0].text.strip()\n",
    "print(mimicked_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate similarity score and improve text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity(sample_texts, mimicked_text):\n",
    "    # Preprocess texts\n",
    "    texts = sample_texts + [mimicked_text]\n",
    "    processed_texts = [re.sub(r'\\W+', ' ', text.lower()) for text in texts]\n",
    "   \n",
    "    # Create TF-IDF vectorizer\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform(processed_texts)\n",
    "   \n",
    "    # Calculate cosine similarity\n",
    "    similarity_scores = cosine_similarity(tfidf_matrix[-1], tfidf_matrix[:-1])\n",
    "    average_similarity = np.mean(similarity_scores)\n",
    "   \n",
    "    return average_similarity\n",
    "\n",
    "similarity_score = calculate_similarity(sample_texts, mimicked_text)\n",
    "\n",
    "# Iteratively improve mimicked text\n",
    "for i in range(num_iterations):\n",
    "    print(f\"Iteration {i+1}\")\n",
    "    print(\"Similarity Score:\", similarity_score)\n",
    "   \n",
    "    if similarity_score >= 0.85:\n",
    "        print(\"Desired similarity score achieved.\")\n",
    "        break\n",
    "   \n",
    "    prompt = f\"Here is the current mimicked text:\\n{mimicked_text}\\n\\nThe similarity score compared to the sample texts is {similarity_score:.2f}. Improve the mimicked text by focusing on capturing the key stylistic elements of the sample texts more accurately.\"\n",
    "    response = client.completions.create(\n",
    "        prompt=prompt,\n",
    "        model=model,\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "        max_tokens=500\n",
    "    )\n",
    "    mimicked_text = response.completions[0].text.strip()\n",
    "    similarity_score = calculate_similarity(sample_texts, mimicked_text)\n",
    "\n",
    "# Provide explanation of similarity score calculation\n",
    "explanation = \"The similarity score was calculated using the following steps:\\n\"\n",
    "explanation += \"1. Preprocess the sample texts and mimicked text by removing non-word characters and converting to lowercase.\\n\"\n",
    "explanation += \"2. Create a TF-IDF vectorizer to convert the texts into numerical feature vectors.\\n\"\n",
    "explanation += \"3. Calculate the cosine similarity between the mimicked text's feature vector and each sample text's feature vector.\\n\"\n",
    "explanation += \"4. Take the average of the cosine similarity scores to obtain the final similarity score.\"\n",
    "print(\"<similarity_score_calculation>\")\n",
    "print(explanation)\n",
    "print(\"</similarity_score_calculation>\")\n",
    "print(\"<similarity_score>\")\n",
    "print(f\"{similarity_score:.2f}\")\n",
    "print(\"</similarity_score>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save text to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final mimicked text to file\n",
    "output_dir = \"outputs/\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_file = os.path.join(output_dir, \"mimicked_text.txt\")\n",
    "with open(output_file, \"w\") as file:\n",
    "    file.write(mimicked_text)\n",
    "print(\"Mimicked text saved to\", output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
