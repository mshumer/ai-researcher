{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Docs: Claude Report Revision\n",
    "Expand for Docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This Python notebook provides a guide on using the Claude Report Revision tool. The notebook includes essential libraries for handling web requests, JSON data, regular expressions, and file operations. It also features a custom function to preprocess textual data by removing specified lines.\n",
    "\n",
    "## Dependencies\n",
    "The following libraries are used in this notebook:\n",
    "- `concurrent.futures`: Provides a high-level interface for asynchronously executing callables.\n",
    "- `anthropic`: Anthropic API client library.\n",
    "- `requests`: Allows sending HTTP requests.\n",
    "- `json`: Enables JSON encoding and decoding.\n",
    "- `ast`: Provides the ability to parse Python expressions.\n",
    "- `re`: Supports regular expressions.\n",
    "- `os`: Provides a way to interact with the operating system.\n",
    "- `googleapiclient.discovery`: Google API client library for service discovery.\n",
    "\n",
    "## Environment Variables\n",
    "The notebook requires the following environment variables to be set:\n",
    "- `ANTHROPIC_API_KEY`: Your Anthropic API key.\n",
    "- `GOOGLE_API_KEY`: Your Google Search API key.\n",
    "- `GOOGLE_CSE_ID`: Your Custom Search Engine ID.\n",
    "\n",
    "Make sure to set these environment variables on your PC or replace the `os.getenv()` calls with your API keys as strings.\n",
    "\n",
    "## Model Selection\n",
    "The notebook allows you to select models for different tasks:\n",
    "- `RESEARCH_MODEL`: The model used for performing the research task (default: \"claude-3-haiku-20240307\").\n",
    "- `REPORT_MODEL`: The model used for generating the final comprehensive report (default: \"claude-3-sonnet-20240229\").\n",
    "\n",
    "## Functions\n",
    "The notebook includes the following functions:\n",
    "\n",
    "### remove_first_line\n",
    "Removes the first line of the given text if it starts with \"Here\" and ends with a colon.\n",
    "\n",
    "### generate_text\n",
    "Generates text using the specified model and prompt. It sends a request to the Anthropic API and returns the generated text after removing the first line.\n",
    "\n",
    "### search_web\n",
    "Performs a web search using the Google Custom Search API. It retrieves the title and snippet of the search results and returns them as a list.\n",
    "\n",
    "### revise_report\n",
    "Analyzes the given research report, generates search queries to gather additional information, performs web searches, and updates the report with the new information. It also identifies and removes redundant or duplicate information.\n",
    "\n",
    "## Usage\n",
    "To use the notebook:\n",
    "1. Set the required environment variables or replace them with your API keys.\n",
    "2. Run the notebook.\n",
    "3. Enter the path to the markdown research report file when prompted.\n",
    "4. The notebook will revise the research report and save the revised version as a new file with the suffix \"_revised.md\" in the same directory.\n",
    "\n",
    "## Error Handling\n",
    "The notebook includes error handling for various scenarios:\n",
    "- If the specified research report file is not found, an error message is displayed, and the program exits.\n",
    "- If an exception occurs during the report revision process, an error message is displayed, and the program exits.\n",
    "- If there are unsupported characters in the generated report, an error message is displayed, and the user is prompted to try again with a different report or modify the generated report to remove the unsupported characters.\n",
    "\n",
    "## Summary\n",
    "This notebook provides a guide on using the Claude Report Revision tool to revise and enhance research reports. It utilizes the Anthropic API and Google Custom Search API to gather additional information and update the report accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import anthropic\n",
    "import requests\n",
    "import json\n",
    "import ast\n",
    "import re\n",
    "import os\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "# SET ENVIRONMENT VARIABLES ON YOUR PC OR REPLACE THE OS.GETENV() WITH YOUR API KEYS AS STRINGS\n",
    "ANTHROPIC_API_KEY = os.getenv(\"ANTHROPIC_API_KEY\")  # Replace with your Anthropic API key\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_SEARCH\")  # Replace with your Google Search API key\n",
    "GOOGLE_CSE_ID = os.getenv(\"GOOGLE_SEARCH_ENGINE_ID\")  # Replace with your Custom Search Engine ID\n",
    "\n",
    "# Select models for tasks\n",
    "RESEARCH_MODEL = \"claude-3-haiku-20240307\"  # set the model which will perform the research task\n",
    "REPORT_MODEL = \"claude-3-sonnet-20240229\"  # set the model which will generate the final comprehensive report\n",
    "\n",
    "client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_first_line(text):\n",
    "    lines = text.strip().split(\"\\n\")\n",
    "    if lines[0].startswith(\"Here\") and lines[0].strip().endswith(\":\"):\n",
    "        return \"\\n\".join(lines[1:])\n",
    "    return text\n",
    "\n",
    "def generate_text(prompt, model, max_tokens=4000, temperature=0.4):\n",
    "    headers = {\n",
    "        \"x-api-key\": ANTHROPIC_API_KEY,\n",
    "        \"anthropic-version\": \"2023-06-01\",\n",
    "        \"content-type\": \"application/json\"\n",
    "    }\n",
    "    data = {\n",
    "        \"model\": model,\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"temperature\": temperature,\n",
    "        \"system\": \"You are a world-class researcher. Analyze the given information and generate a detailed, comprehensive, and well-structured report.\",\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "    }\n",
    "    try:\n",
    "        response = requests.post(\"https://api.anthropic.com/v1/messages\", headers=headers, json=data)\n",
    "        response.raise_for_status()  # Raise an exception for 4xx or 5xx status codes\n",
    "        response_json = response.json()\n",
    "        response_text = response_json['content'][0]['text']\n",
    "        print(remove_first_line(response_text.strip()))\n",
    "        return remove_first_line(response_text.strip())\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        raise Exception(f\"Request failed: {e}\")\n",
    "\n",
    "def search_web(search_term, api_key, cse_id):\n",
    "    try:\n",
    "        service = build(\"customsearch\", \"v1\", developerKey=api_key)\n",
    "        result = service.cse().list(q=search_term, cx=cse_id).execute()\n",
    "        parsed_data = json.loads(json.dumps(result))\n",
    "        relevant_text = []\n",
    "        for item in parsed_data.get('items', []):\n",
    "            title = item.get('title', '')\n",
    "            snippet = item.get('snippet', '')\n",
    "            relevant_text.append(f\"Title: {title}\\nSnippet: {snippet}\\n\")\n",
    "        print(\"\\n\".join(relevant_text))\n",
    "        return relevant_text\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred during web search: {e}\")\n",
    "        return []\n",
    "\n",
    "def revise_report(research_report):\n",
    "    search_data = []\n",
    "    all_queries = []\n",
    "    search_cache = {}\n",
    "\n",
    "    print(\"Analyzing report and generating search queries...\")\n",
    "    analysis_prompt = f\"Analyze the following research report and identify areas of the report that need more detail or further information:\\n\\n{research_report}\\n\\n---\\n\\nGenerate 3 to 5 search queries to gather additional information to enhance the report. Return your queries in a Python-parseable list. Return nothing but the list. Do so in one line. Start your response with [\\\"\"\n",
    "    queries_response = generate_text(analysis_prompt, model=RESEARCH_MODEL)\n",
    "\n",
    "    if queries_response.startswith('[') and ']' in queries_response:\n",
    "        try:\n",
    "            queries = ast.literal_eval(queries_response)\n",
    "        except SyntaxError:\n",
    "            print(\"Error: Invalid search query format. Skipping queries.\")\n",
    "            queries = []\n",
    "    else:\n",
    "        print(\"Error: Search query format not found. Skipping queries.\")\n",
    "        queries = []\n",
    "\n",
    "    all_queries.extend(queries)\n",
    "\n",
    "    def search_and_cache(query):\n",
    "        if query in search_cache:\n",
    "            return search_cache[query]\n",
    "        else:\n",
    "            search_results = search_web(query, GOOGLE_API_KEY, GOOGLE_CSE_ID)\n",
    "            search_cache[query] = search_results\n",
    "            return search_results\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        search_results = list(executor.map(search_and_cache, queries))\n",
    "        search_data.extend(search_results)\n",
    "\n",
    "    print(\"Updating report with additional information...\")\n",
    "    update_prompt = f\"Update the following research report by incorporating the new information from the searches. Additionally, identify areas of the report which are redundant/duplicate areas of information, and make necessary changes to the verbiage ass needed in order to get points across better. However, avoid using hyperbole or terms of grandeur. The goal is to improve this report:\\n\\n{research_report}\\n\\n---\\n\\nAdditional search data:\\n\\n{str(search_data)}\\n\\n---\\n\\nGenerate an updated report that includes the new information and provides more detail in the identified areas. Remember to revise the Table of Contents as needed. Use Markdown for formatting.\"\n",
    "    updated_report = generate_text(update_prompt, model=REPORT_MODEL, max_tokens=4000)\n",
    "    print(\"Report revision completed!\")\n",
    "    return updated_report\n",
    "\n",
    "# User input\n",
    "research_report = input(\"Enter the path to the markdown research report file: \")\n",
    "\n",
    "# Read the research report from the file\n",
    "try:\n",
    "    with open(research_report, \"r\", encoding=\"utf-8\") as file:\n",
    "        report_content = file.read()\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File '{research_report}' not found.\")\n",
    "    exit(1)\n",
    "\n",
    "# Revise the research report\n",
    "revised_report = None\n",
    "try:\n",
    "    revised_report = revise_report(report_content)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# Save the revised report to a file with the format \"[original_filename]_revised.md\" in the same directory\n",
    "if revised_report:\n",
    "    report_filename = os.path.splitext(research_report)[0] + \"_revised.md\"\n",
    "    try:\n",
    "        with open(report_filename, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(revised_report)\n",
    "        print(f\"Revised report saved as '{report_filename}'.\")\n",
    "    except UnicodeEncodeError as e:\n",
    "        print(f\"Error: Unable to save the report due to unsupported characters. Please try again with a different research report or modify the generated report to remove any unsupported characters.\")\n",
    "        print(f\"Error details: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
